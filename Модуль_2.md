# *demoexam 2026*
![image](https://github.com/Demomen-saveTF2/SA1-22demo2025/blob/main/topology.png)
## Задание 1

### Настройте контроллер домена Samba DC на сервере BR-SRV:

- Имя домена au-team.irpo

- Введите в созданный домен машину HQ-CLI

- Создайте 5 пользователей для офиса HQ: имена пользователей формата hquserNo (например hquser1, hquser2 и т.д.)

- Создайте группу hq, введите в группу созданных пользователей

- Убедитесь, что пользователи группы hq имеют право аутентифицироваться на HQ-CLI

- Пользователи группы hq должны иметь возможность повышать привилегии для выполнения ограниченного набора команд: cat, grep, id. Запускать другие команды с повышенными привилегиями пользователи группы права не имеют.

<br/>
<details>
<summary>Решение</summary>
<br/>

#### Настройка контроллера домена Samba DC
```yml
apt-get update 
apt-get install task-samba-dc -y
```
Удаляем изначальную конфигурацию и интерактивно создаём домен командой **`samba-tool domain provision`** и просто несколько раз нажимаем `Enter`, а после вводим пароль **`P@ssw0rd`**
```yml
rm -rf /etc/samba/smb.conf
rm -rf /var/lib/samba
rm -rf /var/cache/samba
mkdir -p /var/lib/samba/sysvol
samba-tool domain provision
```

```yml
mv /etc/krb5.conf /etc/krb5.conf.back 
cp /var/lib/samba/private/krb5.conf /etc/krb5.conf
systemctl enable --now samba
systemctl restart network
systemctl restart samba.service 
```

Проверка:
```yml
samba-tool domain info 127.0.0.1
smbclient -L 127.0.0.1 -U administrator
```

Настроим DNS на BR-SRV:
```yml
samba-tool dns add br-srv.au-team.irpo au-team.irpo hq-srv A 192.168.1.10 -U Administrator
samba-tool dns add br-srv.au-team.irpo au-team.irpo hq-rtr A 192.168.1.1 -U Administrator
samba-tool dns add br-srv.au-team.irpo au-team.irpo br-rtr A 192.168.3.1 -U Administrator
samba-tool dns add br-srv.au-team.irpo au-team.irpo web.au-team.irpo A 172.16.1.1 -U Administrator
samba-tool dns add br-srv.au-team.irpo au-team.irpo docker.au-team.irpo A 172.16.2.1 -U Administrator
samba-tool dns query br-srv.au-team.irpo au-team.irpo @ ALL -U administrator
```

Создание группы и пользователей:
```yml
kinit administrator@AU-TEAM.IRPO
samba-tool group add hq
samba-tool group list

for i in {1..5}; 
do
  samba-tool user add hquser$i P@ssw0rd;
  samba-tool user setexpiry hquser$i --noexpiry;
  samba-tool group addmembers "hq" hquser$i;
  samba-tool user enable hquser$i;
done

samba-tool group listmembers hq
```

Меняем файл resolv.conf на BR-SRV:
```yml
echo "search au-team.irpo" > /etc/net/ifaces/ens18/resolv.conf
echo "nameserver 127.0.0.1" >> /etc/net/ifaces/ens18/resolv.conf
```

#### Переходим на HQ-CLI (работаем в графической оболочке)
Вручную меняем конфигурацию на статическую и задаем BR-SRV в качестве DNS-сервера. Так же советую поменять сетевую подсистему на Etcnet.
Заходим в центр управления ► центр управления системой ► `Ethernet-интерфейсы`:
<img width="1323" height="747" alt="Центр упрввления системой" src="https://github.com/user-attachments/assets/9d0d91f6-b852-4aa7-907e-7e31e833280e" />

После преходим во вкладку Аутентицфикация, выбираем `Домен Active Directory` и вбиваем домен:
Нажимаем `Применить` и вводим **пароль**, что задали **при создания домена** на BR-SRV
<img width="1227" height="257" alt="Ввод в домен" src="https://github.com/user-attachments/assets/8c0a9041-01df-42df-a689-d909880e3cbb" />

После появления такого окошка перезагружаем клиента и заходим за доменного пользователя:
<img width="429" height="286" alt="вход за доменного пользлвателя" src="https://github.com/user-attachments/assets/b1b0bf6c-0b68-43dd-ae0e-5e32abe07b66" />


#### Настройка прав доступа:
Как только удастся зайти за доменного пользователя, переходим в терминал и работаем от root:

```yml
apt-get update && apt-get install libnss-role -y
```

```yml
control libnss-role
roleadd hq wheel
echo "WHEEL_USERS ALL=(ALL:ALL) /usr/bin/cat, /usr/bin/grep, /usr/bin/id" >> /etc/sudoers
tail /etc/sudoers
```

Перезагружаем и заходим доменным пользователем, выполняем sudo id, чтобы проверить появились ли права.

<br/>
</details>
<br/>


## Задание 2

### Сконфигурируйте файловое хранилище на сервере HQ-SRV:

- При помощи двух подключенных к серверу дополнительных дисков размером 1 Гб сконфигурируйте дисковый массив уровня 0

- Имя устройства – md0, при необходимости конфигурация массива размещается в файле /etc/mdadm.conf

- Создайте раздел, отформатируйте раздел, в качестве файловой системы используйте ext4

- Обеспечьте автоматическое монтирование в папку /raid


<br/>
<details>
<summary>Решение</summary>
<br/>

#### Настройка массива 

Находим названия тех дисков, что размером в 1 Гб, для этого введём команду `lsblk`. 
```yml
lsblk
```

Создание массива. Обратите внимание какого уровня массив нужно создать по вашему варианту. Для этого изменяем значение `--level=`. Если у вас несколько устройств - меняем уже значение `--raid-devices=`, после пишем путь к дискам через пробел `/dev/sdb1 /dev/sdc1`

```yml
mdadm --create /dev/md0 --level=0 --raid-devices=2 /dev/sdb1 /dev/sdc1
mdadm --detail --scan >> /etc/mdadm.confmkfs.ext4 /dev/md0
mkdir /raid
cp /etc/fstab /etc/fstab.back
echo "/dev/md0 /raid ext4 defaults 0 0	" >> /etc/fstab
mount -av
df -T
```

<br/>
</details>
<br/>

## Задание 3

### Настройте сервер сетевой файловой системы (nfs) на HQ-SRV:

- В качестве папки общего доступа выберите /raid/nfs, доступ для чтения и записи исключительно для сети в сторону HQ-CLI

- На HQ-CLI настройте автомонтирование в папку /mnt/nfs

- Основные параметры сервера отметьте в отчёте

<br/>
<details>
<summary>Решение</summary>
<br/>

#### Настройка общей папки 

```yml
apt-get update && apt-get install nfs-server nfs-utils -y
mkdir /raid/nfs
chmod 777 /raid/nfs
cp /etc/exports /etc/exports.back
echo "/raid/nfs 192.168.2.0/27(rw,no_subtree_check,no_root_squash)" >> /etc/exports
systemctl enable --now nfs-server
```

#### Переходим на HQ-CLI.

```yml
apt-get update && apt-get install nfs-utils nfs-clients -y
mkdir /mnt/nfs
chmod -R 777 /mnt/nfs
showmount -e hq-srv
cp /etc/fstab /etc/fstab.back
echo "192.168.0.10:/raid/nfs	/mnt/nfs	nfs	defaults	0	0" >> /etc/fstab
mount -av
df -T
```
> Обратите внимание на табы в файле `fstab`

<br/>
</details>
<br/>

## Задание 4

### Настройте службу сетевого времени на базе сервиса chrony на маршрутизаторе ISP:

- Вышестоящий сервер ntp на маршрутизаторе ISP - на выбор участника

- Стратум сервера - 5

- В качестве клиентов ntp настройте: HQ-SRV, HQ-CLI, BR-RTR, BR-SRV

<br/>
<details>
<summary>Решение</summary>
<br/>

#### Настройка службы сетевого времени ISP
```yml
sed -i 's/pool pool.ntp.org iburst/pool pool.ntp.org iburst prefer minstratum 4/' /etc/chrony.conf | grep pool /etc/chrony.conf
sed -i 's/\#local stratum 10/local stratum 5/' /etc/chrony.conf | grep "local stratum" /etc/chrony.conf
systemctl restart chronyd
```
#### Настройка клиентов:
#### На HQ-SRV, HQ-CLI
```yml
apt-get update && apt-get install chrony
echo "server 172.16.1.1 iburst" >> /etc/chrony.conf
systemctl restart chronyd
chronyc sources
```

#### На BR-SRV
```yml
apt-get update && apt-get install chrony
echo "server 172.16.2.1 iburst" >> /etc/chrony.conf
systemctl restart chronyd
chronyc sources
```

#### На HQ-RTR
```yml
conf
ntp server 172.16.1.1
end
wr mem
```

#### На BR-RTR
```yml
conf
ntp server 172.16.2.1
end
wr mem
```

<br/>
</details>
<br/>

## Задание 5 (нужно проверить, будет ли работать не передавая ключи ssh)

### Сконфигурируйте ansible на сервере BR-SRV:

- Сформируйте файл инвентаря, в инвентарь должны входить HQ-SRV, HQ-CLI, HQ-RTR и BR-RTR

- Рабочий каталог ansible должен располагаться в /etc/ansible

- Все указанные машины должны без предупреждений и ошибок отвечать pong на команду ping в ansible посланную с BR-SRV

<br/>
<details>
<summary>Решение</summary>
<br/>

#### Настройка службы ansible

```yml
apt-get install ansible sshpass -y
```

Редактируем файл `/etc/ansible/ansible.cfg`. Пишем строки в конце блока `some basic default values`
```yml
nano /etc/ansible/ansible.cfg
```
```yml
interpreter_python=auto_silent
host_key_checking = False
```

```yml
ansible-galaxy collection install ansible.netcommon
ansible-galaxy collection install cisco.ios
apt-get install –y python3-module-pip
pip3 install ansible-pylibssh
```

Сформируем файл инвентаря
```yml
cat << EOF >/etc/ansible/hosts
HQ-CLI ansible_user=sshuser ansible_password=P@ssw0rd ansible_port=2026
HQ-SRV ansible_user=sshuser ansible_password=P@ssw0rd ansible_port=2026
HQ-RTR ansible_host=192.168.1.1 ansible_user=admin ansible_password=admin ansible_connection=network_cli ansible_network_os=ios
BR-RTR ansible_host=192.168.3.1 ansible_user=admin ansible_password=admin ansible_connection=network_cli ansible_network_os=ios
EOF
```

Пингуем
```yml
ansible all -m ping
```
<br/>
</details>
<br/>


## Задание 6 (в конце нужен скрин)

### Разверните веб приложение в docker на сервере BR-SRV:

- Средствами docker должен создаваться стек контейнеров с веб приложением и базой данных

- Используйте образы site_latest и mariadb_latest располагающиеся в директории docker в образе Additional.iso

- Основной контейнер testapp должен называться tespapp

- Контейнер с базой данных должен называться db

- Импортируйте образы в docker, укажите в yaml файле параметры подключения к СУБД, имя БД - testdb, пользователь test с паролем P@ssw0rd, порт приложения 8080, при необходимости другие параметры

- Приложение должно быть доступно для внешних подключений через порт 8080

<br/>
<details>
<summary>Решение</summary>
<br/>

#### Настройка службы docker 

```yml
apt-get install docker-engine docker-compose-v2 -y
```

Монтируем Additional.iso в директорию /mnt, чтобы скачать необходимые штучки)
```yml
systemctl enable --now docker.service
mount -o loop /dev/sr0 /mnt/ -v
ls -l /mnt/docker/
```

Качаем
```yml
docker load < /mnt/docker/site_latest.tar
docker load < /mnt/docker/mariadb_latest.tar
```

Создадим файл docker-compose
> Посмотрите порты названия приложения/базы данных, пароли и тд по вашему варианту. В целом, тут не сложно разобраться что куда вписать
```yml
cat << EOF > docker-compose.yml
services:
  database:
    container_name: db
    image: mariadb:latest
    restart: always
    ports: 
      - "3306:3306"
    environment:
      MARIADB_DATABASE: testdb
      MARIADB_USER: test
      MARIADB_PASSWORD: P@ssw0rd
      MARIADB_ROOT_PASSWORD: P@ssw0rd
    volumes:
      - db_data:/var/lib/mysql
      
  app:
    container_name: testapp
    image: site:latest
    restart: always
    ports: 
      - "8080:8000"
    environment: 
      DB_HOST: database
      DB_PORT: 3306
      DB_NAME: testdb
      DB_USER: test
      DB_PASS: P@ssw0rd
      DB_TYPE: maria
    depends_on: 
      - database
volumes:
  db_data:
EOF
```

Проверить на наличие ошибок файл docker-compose можно следующей командой:
```yml
docker compose config
```

Запустим и проверим набор контейнеров:
```yml
docker compose up -d
docker ps
```

Для проверки переходим на HQ-CLI, открываем браузер и вбиваем в поисковик **адрес BR-SRV** с портом **8080**
<img width="1335" height="384" alt="Снимок экрана 2026-02-16 150408" src="https://github.com/user-attachments/assets/b8163c9e-4c65-40fb-bebb-1ea93d7911a4" />

<br/>
</details>
<br/>

## Задание 7

### Разверните веб приложение на сервере HQ-SRV:

- Используйте веб-сервер apache

- В качестве системы управления базами данных используйте mariadb

- Файлы веб приложения и дамп базы данных находятся в директории web образа Additional.iso

- Выполните импорт схемы и данных из файла dump.sql в базу данных webdb

- Создайте пользователя web с паролем P@ssw0rd и предоставьте ему права доступа к этой базе данных

- Файлы index.php и директорию images скопируйте в каталог веб сервера apache

- В файле index.php укажите правильные учётные данные для подключения к БД

- Запустите веб сервер и убедитесь в работоспособности приложения

- Основные параметры отметьте в отчёте

<br/>
<details>
<summary>Решение</summary>
<br/>

#### Настройка веб приложения

```yml
apt-get install lamp-server -y
```

Монтируем Additional.iso в директорию /mnt, чтобы скачать необходимые штучки)
```yml
mount -o loop /dev/sr0 /mnt/ -v
cp /mnt/web/index.php /var/www/html 
cp /mnt/web/logo.png /var/www/html
```

Укажем правильные учётные данные для подключения ка БД в файле `/var/www/html/index.php`
```yml
nano  /var/www/html/index.php
```
Редактируем этот блок:
```
	$servername = "localhost";
	$username = "web";
	$password = "P@ssw0rd";
	$dbname = "webdb";
```

```yml
systemctl enable --now mariadb
```

Создаем БД
```yml
mariadb -e "CREATE DATABASE webdb;"
mariadb -e "
CREATE USER 'web'@'localhost' IDENTIFIED BY 'P@ssw0rd';
GRANT ALL PRIVILEGES ON webdb.* TO 'web'@'localhost';
"
```

```yml
mariadb webdb < /mnt/web/dump.sql
mariadb -e "USE webdb; SHOW TABLES;"
systemctl enable --now httpd2.service
```

Для проверки переходим на HQ-CLI, открываем браузер и вбиваем в поисковик **адрес HQ-SRV** без указания порта
<img width="1184" height="323" alt="Снимок экрана 2026-02-16 150604" src="https://github.com/user-attachments/assets/957c121a-d333-4fc0-9d3d-de5560305b73" />

<br/>
</details>
<br/>

## Задание 8 (написать как проверить)

### На маршрутизаторах сконфигурийте статическую трансляцию портов:

- Пробросьте порт 8080 в порт приложения testapp BR-SRV на маршрутизаторе BR-RTR, для обеспечения работы приложения testapp извне

- Пробросьте порт 8080 в порт веб приложения на HQ-SRV на маршрутизаторе HQ-RTR, для обеспечения работы веб приложения извне

- Пробросьте порт 2026 на маршрутизаторе HQ-RTR в порт 2026 сервера HQ-SRV, для подключения к серверу по протоколу ssh из внешних сетей

- Пробросьте порт 2026 на маршрутизаторе BR-RTR в порт 2026 сервера BR-SRV, для подключения к серверу по протоколу ssh из внешних сетей.


<br/>
<details>
<summary>Решение</summary>
<br/>

#### Настройка трансляции портов
Поясняю команду на пальцах: сначала пишем IP-адрес роутера смотрящий во внутреннюю сеть, порт HTTP, дальше IP-адрес смотрящий в сторону ISP, порт по варианту (в нашем случае 8080)

Вот так это выглядит:
```yml
ip nat source static tcp <IP-АДРЕС_УСТРОЙСТВА_ЛОКАЛЬНОЙ_СЕТИ> <ПОРТ_УСТРОЙСТВА_ЛОКАЛЬНОЙ_СЕТИ> <ВНЕШНИЙ_IP-АДРЕС_УСТРОЙСТВА> <ПОРТ_ДЛЯ_ОБРАЩЕНИЯ_ИЗ_ВНЕШНЕЙ_СЕТИ>
```

HQ-RTR:
```yml
conf
ip nat source static tcp 192.168.100.2 80 172.16.1.2 8080
ip nat source static tcp 192.168.100.2 2026 172.16.1.2 2026
end
wr mem
```

BR-RTR:
```yml
conf
ip nat source static tcp 192.168.0.2 8080 172.16.2.2 8080
ip nat source static tcp 192.168.0.2 2026 172.16.2.2 2026
end
wr mem
```

<br/>
</details>
<br/>

## Задание 9

### Настройте веб-сервер nginx как обратный прокси-сервер на ISP:

- При обращении по доменному имени web.au-team.irpo у клиента должно открываться веб приложение на HQ-SRV

- При обращении по доменному имени docker.au-team.irpo клиента должно открываться веб приложение testapp

- Перенастройте ранее настроенный реверсивный прокси nginx на протокол https (перенесено из модуля 3, но в модуле 2)


<br/>
<details>
<summary>Решение</summary>
<br/>

#### Настройка nginx
```yml
apt-get update && apt-get install nginx -y
```

Настроитм nginx как реверсивный прокси сервер, приведя файл /etc/nginx/sites-available.d/r-proxy.conf к следующему виду 
> здесь есть стоки для web-based аутентификации, поэтому на следующем задании можем не открывать этот файл
```yml
cat << "EOF" > /etc/nginx/sites-available.d/r-proxy.conf
server {
    listen 80;
    server_name web.au-team.irpo;

    location / {
        proxy_pass http://172.16.1.2:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        auth_basic "Restricted Access";
        auth_basic_user_file /etc/nginx/.htpasswd;
    }
}

server {
    listen 80;
    server_name docker.au-team.irpo;

    location / {
        proxy_pass http://172.16.2.2:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
EOF
```

```yml
ln -s /etc/nginx/sites-available.d/r-proxy.conf /etc/nginx/sites-enabled.d/
```
```yml
nginx -t
systemctl enable --now nginx
systemctl status nginx
```

Для проверки переходим на HQ-CLI, открываем браузер и вбиваем в поисковик docker.au-team.irpo, web.au-team.irpo (не откроется, пока будет выполнено 10 задание из-за строчек для web-based аутентификации) 
<img width="1287" height="276" alt="Снимок экрана 2026-02-16 151058" src="https://github.com/user-attachments/assets/d6bc101c-a02e-40c1-8f50-1ccae56f21f6" />
<img width="1348" height="298" alt="Снимок экрана 2026-02-16 151104" src="https://github.com/user-attachments/assets/cef45290-2624-4d13-ab2e-a1c0e87a617c" />


<br/>
</details>
<br/>

## Задание 10

### На маршрутизаторе ISP настройте web-based аутентификацию:

- При обращении к сайту web.au-team.irpo клиенту должно быть предложено ввести аутентификационные данные

- В качестве логина для аутентификации выберите WEB с паролем P@ssw0rd

- Выберите файл /etc/nginx/.htpasswd в качестве хранилища учётных записей

- При успешной аутентификации клиент должен перейти на веб сайт.

<br/>
<details>
<summary>Решение</summary>
<br/>

#### Настройка web-based аутентификации 
```yml
apt-get install apache2-htpasswd -y
```

Создаем пользователя и зададим пароль:
```yml
htpasswd -c /etc/nginx/.htpasswd WEB
```

```yml
cat /etc/nginx/.htpasswd
nginx -t
systemctl restart nginx
```

Для проверки переходим на HQ-CLI, открываем web.au-team.irpo, вводим логин и пароль
> Здесь нужен скрин

<br/>
</details>
<br/>

## Задание 11

### Удобным способом установите приложение Яндекс Браузер на HQ-CLI:

- Установку браузера отметьте в отчёте.

<br/>
<details>
<summary>Решение</summary>
<br/>

#### Установка браузера

```yml
apt-get update 
apt-get install yandex-browser-stable -y
```

<br/>
</details>
<br/>
